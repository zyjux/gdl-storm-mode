{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c382a586-0788-4082-ac32-8e0d5b57fc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "from tensorflow.keras import layers, models\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imports.GDL_layers as GDL_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3215de71-47ec-42e4-9ee1-3d8f3d73edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a list of all the datafiles\n",
    "patch_path = \"/glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/\"\n",
    "patch_files = sorted(glob(join(patch_path, \"*.nc\")))\n",
    "patch_ds = xr.open_dataset(patch_files[0])\n",
    "csv_path = \"/glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/\"\n",
    "csv_files = sorted(glob(join(csv_path, \"track_step_*.csv\")))\n",
    "meta_ds = pd.read_csv(csv_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f10a4600-43c3-49f1-8d52-b64657768946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20101024-0000_d01_model_patches.nc\n",
      "Train 10, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20110201-0000_d01_model_patches.nc\n",
      "Train 20, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20110326-0000_d01_model_patches.nc\n",
      "Train 30, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20110414-0000_d01_model_patches.nc\n",
      "Train 40, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20110425-0000_d01_model_patches.nc\n",
      "Train 50, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20110522-0000_d01_model_patches.nc\n",
      "Train 60, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20110605-0000_d01_model_patches.nc\n",
      "Train 70, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20110615-0000_d01_model_patches.nc\n",
      "Train 80, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20110625-0000_d01_model_patches.nc\n",
      "Train 90, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20110712-0000_d01_model_patches.nc\n",
      "Train 100, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20120218-0000_d01_model_patches.nc\n",
      "Validation 105, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20120315-0000_d01_model_patches.nc\n",
      "Validation 115, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20120401-0000_d01_model_patches.nc\n",
      "Test 120, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20120409-0000_d01_model_patches.nc\n",
      "Test 130, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20120503-0000_d01_model_patches.nc\n",
      "Test 140, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20120529-0000_d01_model_patches.nc\n"
     ]
    }
   ],
   "source": [
    "# Pull selected variables from patch files and join into a single DataSet\n",
    "num_files = 150\n",
    "train_split = int(num_files*0.7)\n",
    "val_split = int(num_files*0.8)\n",
    "variables = [\"REFL_COM_curr\", \"masks\"]\n",
    "data_list = []\n",
    "for p, patch_file in enumerate(patch_files[0:train_split]):\n",
    "    if p % 10 == 0:\n",
    "        print(f'Train {p}, {patch_file}')\n",
    "    ds = xr.open_dataset(patch_file)\n",
    "    data_list.append(ds[variables].compute())\n",
    "    ds.close()\n",
    "input_train = xr.concat(data_list, dim=\"p\")[\"REFL_COM_curr\"].expand_dims(\"channel\", axis = -1)\n",
    "train_masks = xr.concat(data_list, dim=\"p\")[\"masks\"]\n",
    "data_list = []\n",
    "for p, patch_file in enumerate(patch_files[train_split:val_split]):\n",
    "    if p % 10 == 0:\n",
    "        print(f'Validation {train_split + p}, {patch_file}')\n",
    "    ds = xr.open_dataset(patch_file)\n",
    "    data_list.append(ds[variables].compute())\n",
    "    ds.close()\n",
    "input_val = xr.concat(data_list, dim=\"p\")[\"REFL_COM_curr\"].expand_dims(\"channel\", axis = -1)\n",
    "val_masks = xr.concat(data_list, dim=\"p\")[\"masks\"]\n",
    "data_list = []\n",
    "for p, patch_file in enumerate(patch_files[val_split:num_files]):\n",
    "    if p % 10 == 0:\n",
    "        print(f'Test {val_split + p}, {patch_file}')\n",
    "    ds = xr.open_dataset(patch_file)\n",
    "    data_list.append(ds[variables].compute())\n",
    "    ds.close()\n",
    "input_test = xr.concat(data_list, dim=\"p\")[\"REFL_COM_curr\"].expand_dims(\"channel\", axis = -1)\n",
    "test_masks = xr.concat(data_list, dim=\"p\")[\"masks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eef87aa-7f51-48ff-8c77-fca32f52313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20101024-0000.csv\n",
      "Train 10, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20110201-0000.csv\n",
      "Train 20, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20110326-0000.csv\n",
      "Train 30, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20110414-0000.csv\n",
      "Train 40, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20110425-0000.csv\n",
      "Train 50, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20110522-0000.csv\n",
      "Train 60, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20110605-0000.csv\n",
      "Train 70, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20110615-0000.csv\n",
      "Train 80, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20110625-0000.csv\n",
      "Train 90, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20110712-0000.csv\n",
      "Train 100, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20120218-0000.csv\n",
      "Validation 105, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20120315-0000.csv\n",
      "Validation 115, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20120401-0000.csv\n",
      "Test 120, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20120409-0000.csv\n",
      "Test 130, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20120503-0000.csv\n",
      "Test 140, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20120529-0000.csv\n"
     ]
    }
   ],
   "source": [
    "# Pull variables from csv files and join into an array\n",
    "csv_variables = [\"major_axis_length\", \"minor_axis_length\"]\n",
    "csv_data_list = []\n",
    "for p, csv_file in enumerate(csv_files[0:train_split]):\n",
    "    if p % 10 == 0:\n",
    "        print(f'Train {p}, {csv_file}')\n",
    "    csv_ds = pd.read_csv(csv_file)\n",
    "    csv_data_list.append(csv_ds[csv_variables].to_xarray().rename({'index': 'p'}))\n",
    "output_train = xr.concat(csv_data_list, dim=\"p\").to_array().transpose()\n",
    "csv_data_list = []\n",
    "for p, csv_file in enumerate(csv_files[train_split:val_split]):\n",
    "    if p % 10 == 0:\n",
    "        print(f'Validation {train_split + p}, {csv_file}')\n",
    "    csv_ds = pd.read_csv(csv_file)\n",
    "    csv_data_list.append(csv_ds[csv_variables].to_xarray().rename({'index': 'p'}))\n",
    "output_val = xr.concat(csv_data_list, dim=\"p\").to_array().transpose()\n",
    "csv_data_list = []\n",
    "for p, csv_file in enumerate(csv_files[val_split:num_files]):\n",
    "    if p % 10 == 0:\n",
    "        print(f'Test {val_split + p}, {csv_file}')\n",
    "    csv_ds = pd.read_csv(csv_file)\n",
    "    csv_data_list.append(csv_ds[csv_variables].to_xarray().rename({'index': 'p'}))\n",
    "output_test = xr.concat(csv_data_list, dim=\"p\").to_array().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a33c86c-774e-4742-b98b-5b45130ee9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34061, 144, 144, 1)\n",
      "(4300, 144, 144, 1)\n",
      "(12985, 144, 144, 1)\n",
      "(34061, 2)\n",
      "(4300, 2)\n",
      "(12985, 2)\n"
     ]
    }
   ],
   "source": [
    "print(input_train.shape)\n",
    "print(input_val.shape)\n",
    "print(input_test.shape)\n",
    "print(output_train.shape)\n",
    "print(output_val.shape)\n",
    "print(output_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9ad7e74-ae51-4d6e-bdbf-b42fbf88ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the training data\n",
    "scale_stats = pd.DataFrame(index=[0], columns=[\"mean\", \"sd\"])\n",
    "scale_stats.loc[0, \"mean\"] = input_train.mean()\n",
    "scale_stats.loc[0, \"sd\"] = input_train.std()\n",
    "input_train_norm = (input_train - scale_stats.loc[0, \"mean\"]) / scale_stats.loc[0, \"sd\"]\n",
    "input_val_norm = (input_val - scale_stats.loc[0, \"mean\"]) / scale_stats.loc[0, \"sd\"]\n",
    "input_test_norm = (input_test - scale_stats.loc[0, \"mean\"]) / scale_stats.loc[0, \"sd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95788ec1-4803-4aff-aa8e-84c05ce30e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize output data\n",
    "output_scale_stats = pd.DataFrame(index=[0], columns=[\"mean\", \"sd\"])\n",
    "output_scale_stats.loc[0, \"mean\"] = output_train.mean()\n",
    "output_scale_stats.loc[0, \"sd\"] = output_train.std()\n",
    "output_train_norm = (output_train - output_scale_stats.loc[0, \"mean\"]) / output_scale_stats.loc[0, \"sd\"]\n",
    "output_val_norm = (output_val - output_scale_stats.loc[0, \"mean\"]) / output_scale_stats.loc[0, \"sd\"]\n",
    "output_test_norm = (output_test - output_scale_stats.loc[0, \"mean\"]) / output_scale_stats.loc[0, \"sd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e7ebf37-b8d9-4e9c-963c-e7ccfc8a5cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-19 10:38:06.601075: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-19 10:38:11.606624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30987 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b2:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "ricnn_backbone = models.Sequential()\n",
    "ricnn_backbone.add(GDL_layers.RotEquivConv2D(32, (3, 3), rot_axis=False, input_shape=(144, 144, 1)))\n",
    "ricnn_backbone.add(GDL_layers.RotEquivPool2D((2, 2)))\n",
    "ricnn_backbone.add(GDL_layers.RotEquivConv2D(32, (3, 3)))\n",
    "ricnn_backbone.add(GDL_layers.RotEquivPool2D((2, 2)))\n",
    "ricnn_backbone.add(GDL_layers.RotEquivConv2D(64, (3, 3)))\n",
    "ricnn_backbone.add(GDL_layers.RotEquivPool2D((2, 2)))\n",
    "ricnn_backbone.add(GDL_layers.RotEquivConv2D(64, (3, 3)))\n",
    "ricnn_backbone.add(GDL_layers.RotEquivPool2D((2, 2)))\n",
    "ricnn_backbone.add(GDL_layers.RotEquivConv2D(128, (3, 3)))\n",
    "ricnn_backbone.add(GDL_layers.RotInvPool())\n",
    "ricnn_backbone.add(layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e544f6a4-9369-42c1-8286-bdb364ac7c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rot_equiv_conv2d (RotEquivC  (None, 142, 142, 4, 32)  320       \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " rot_equiv_pool2d (RotEquivP  (None, 71, 71, 4, 32)    0         \n",
      " ool2D)                                                          \n",
      "                                                                 \n",
      " rot_equiv_conv2d_1 (RotEqui  (None, 69, 69, 4, 32)    9248      \n",
      " vConv2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_pool2d_1 (RotEqui  (None, 34, 34, 4, 32)    0         \n",
      " vPool2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_conv2d_2 (RotEqui  (None, 32, 32, 4, 64)    18496     \n",
      " vConv2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_pool2d_2 (RotEqui  (None, 16, 16, 4, 64)    0         \n",
      " vPool2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_conv2d_3 (RotEqui  (None, 14, 14, 4, 64)    36928     \n",
      " vConv2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_pool2d_3 (RotEqui  (None, 7, 7, 4, 64)      0         \n",
      " vPool2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_conv2d_4 (RotEqui  (None, 5, 5, 4, 128)     73856     \n",
      " vConv2D)                                                        \n",
      "                                                                 \n",
      " rot_inv_pool (RotInvPool)   (None, 5, 5, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3200)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,848\n",
      "Trainable params: 138,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ricnn_backbone.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fa0fca9-7db0-435b-8310-257ef53097d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_backbone = models.Sequential()\n",
    "cnn_backbone.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(144, 144, 1)))\n",
    "cnn_backbone.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_backbone.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "cnn_backbone.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_backbone.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn_backbone.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_backbone.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn_backbone.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_backbone.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "cnn_backbone.add(layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3eea481-1265-4bac-a4a9-6c2001d03650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 142, 142, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 71, 71, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 69, 69, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 34, 34, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 5, 5, 128)         73856     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3200)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,848\n",
      "Trainable params: 138,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_backbone.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12d24ae7-8a1e-4b3f-8042-6c291f744eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "head = models.Sequential()\n",
    "head.add(layers.Dense(32, input_shape=(3200,)))\n",
    "head.add(layers.LeakyReLU(alpha=0.05))\n",
    "head.add(layers.Dense(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5039296d-0018-4a03-89ee-48228e92df09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                102432    \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102,498\n",
      "Trainable params: 102,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "head.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11bcc61a-0f29-45ad-86cd-5aec8c87cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = models.Sequential()\n",
    "cnn_model.add(cnn_backbone)\n",
    "cnn_model.add(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e26dd17c-52d7-439e-ac03-ba838ca7271e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_1 (Sequential)   (None, 3200)              138848    \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, 2)                 102498    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 241,346\n",
      "Trainable params: 241,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c333dbb-cb5d-4d98-801b-0e41343ca6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mse']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c1633e5-64e9-43a9-9c62-bb56995db659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-19 10:41:13.697790: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1065/1065 [==============================] - ETA: 0s - loss: 0.3222 - mse: 0.3222WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "1065/1065 [==============================] - 20s 12ms/step - loss: 0.3222 - mse: 0.3222 - val_loss: 0.1529 - val_mse: 0.1529\n",
      "Epoch 2/10\n",
      "1065/1065 [==============================] - 14s 13ms/step - loss: 0.1852 - mse: 0.1852 - val_loss: 0.1199 - val_mse: 0.1199\n",
      "Epoch 3/10\n",
      "1065/1065 [==============================] - 12s 11ms/step - loss: 0.1364 - mse: 0.1364 - val_loss: 0.0925 - val_mse: 0.0925\n",
      "Epoch 4/10\n",
      "1065/1065 [==============================] - 12s 11ms/step - loss: 0.1079 - mse: 0.1079 - val_loss: 0.0799 - val_mse: 0.0799\n",
      "Epoch 5/10\n",
      "1065/1065 [==============================] - 12s 11ms/step - loss: 0.0836 - mse: 0.0836 - val_loss: 0.0666 - val_mse: 0.0666\n",
      "Epoch 6/10\n",
      "1065/1065 [==============================] - 12s 11ms/step - loss: 0.0688 - mse: 0.0688 - val_loss: 0.0665 - val_mse: 0.0665\n",
      "Epoch 7/10\n",
      "1065/1065 [==============================] - 12s 11ms/step - loss: 0.0603 - mse: 0.0603 - val_loss: 0.0683 - val_mse: 0.0683\n",
      "Epoch 8/10\n",
      "1065/1065 [==============================] - 12s 11ms/step - loss: 0.0509 - mse: 0.0509 - val_loss: 0.0641 - val_mse: 0.0641\n",
      "Epoch 9/10\n",
      "1065/1065 [==============================] - 11s 11ms/step - loss: 0.0439 - mse: 0.0439 - val_loss: 0.0553 - val_mse: 0.0553\n",
      "Epoch 10/10\n",
      "1065/1065 [==============================] - 12s 11ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0485 - val_mse: 0.0485\n"
     ]
    }
   ],
   "source": [
    "cnn_hist = cnn_model.fit(x=input_train_norm, y=output_train_norm, epochs=10, validation_data=(input_val_norm, output_val_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2c0d2d4-5efd-4564-bf4f-f0b1add0bc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "1065/1065 [==============================] - 7s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "cnn_latent_train = cnn_backbone.predict(input_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e53367fd-571d-495f-a54e-9a6bc84b977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricnn_backbone.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mse']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e842a53-c87b-49f5-8297-df9eb15d60d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "Epoch 1/10\n",
      "1065/1065 [==============================] - 69s 61ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 2/10\n",
      "1065/1065 [==============================] - 65s 61ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 3/10\n",
      "1065/1065 [==============================] - 65s 61ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 4/10\n",
      "1065/1065 [==============================] - 65s 61ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 5/10\n",
      "1065/1065 [==============================] - 65s 61ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 6/10\n",
      "1065/1065 [==============================] - 65s 61ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 7/10\n",
      "1065/1065 [==============================] - 65s 61ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 8/10\n",
      "1065/1065 [==============================] - 65s 61ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 9/10\n",
      "1065/1065 [==============================] - 65s 61ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 10/10\n",
      "1065/1065 [==============================] - 65s 61ms/step - loss: 0.0055 - mse: 0.0055\n"
     ]
    }
   ],
   "source": [
    "latent_ricnn_cnn_hist = ricnn_backbone.fit(x=input_train_norm, y=cnn_latent_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b808ffc1-7c0a-41f0-8eb6-b369561a5ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ac784f26fe0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "F, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.plot(latent_ricnn_cnn_hist.history['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d585a7f-0075-458b-95fb-4de7fc1599fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lricnn_model = models.Sequential()\n",
    "lricnn_model.add(ricnn_backbone)\n",
    "lricnn_model.add(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb6db518-6841-4709-8606-426fd2683f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lricnn_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mse']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11d6df22-83ee-479b-8a6e-65b69cd433a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 3200)              138848    \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, 2)                 102498    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 241,346\n",
      "Trainable params: 241,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lricnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f56f0ad-bf3a-4c17-b80a-53320dd47717",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricnn_model = models.Sequential()\n",
    "ricnn_model.add(GDL_layers.RotEquivConv2D(32, (3, 3), rot_axis=False, kernel_regularizer='L2', input_shape=(144, 144, 1)))\n",
    "ricnn_model.add(GDL_layers.RotEquivPool2D((2, 2)))\n",
    "ricnn_model.add(GDL_layers.RotEquivConv2D(32, (3, 3)))\n",
    "ricnn_model.add(GDL_layers.RotEquivPool2D((2, 2)))\n",
    "ricnn_model.add(GDL_layers.RotEquivConv2D(64, (3, 3)))\n",
    "ricnn_model.add(GDL_layers.RotEquivPool2D((2, 2)))\n",
    "ricnn_model.add(GDL_layers.RotEquivConv2D(64, (3, 3)))\n",
    "ricnn_model.add(GDL_layers.RotEquivPool2D((2, 2)))\n",
    "ricnn_model.add(GDL_layers.RotEquivConv2D(128, (3, 3)))\n",
    "ricnn_model.add(GDL_layers.RotInvPool())\n",
    "ricnn_model.add(layers.Flatten())\n",
    "ricnn_model.add(layers.Dense(32, activation='relu'))\n",
    "ricnn_model.add(layers.Dense(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5875404d-3a75-443f-b10b-ba5f1457232c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rot_equiv_conv2d_5 (RotEqui  (None, 142, 142, 4, 32)  320       \n",
      " vConv2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_pool2d_4 (RotEqui  (None, 71, 71, 4, 32)    0         \n",
      " vPool2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_conv2d_6 (RotEqui  (None, 69, 69, 4, 32)    9248      \n",
      " vConv2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_pool2d_5 (RotEqui  (None, 34, 34, 4, 32)    0         \n",
      " vPool2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_conv2d_7 (RotEqui  (None, 32, 32, 4, 64)    18496     \n",
      " vConv2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_pool2d_6 (RotEqui  (None, 16, 16, 4, 64)    0         \n",
      " vPool2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_conv2d_8 (RotEqui  (None, 14, 14, 4, 64)    36928     \n",
      " vConv2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_pool2d_7 (RotEqui  (None, 7, 7, 4, 64)      0         \n",
      " vPool2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_conv2d_9 (RotEqui  (None, 5, 5, 4, 128)     73856     \n",
      " vConv2D)                                                        \n",
      "                                                                 \n",
      " rot_inv_pool_1 (RotInvPool)  (None, 5, 5, 128)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 3200)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                102432    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 241,346\n",
      "Trainable params: 241,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ricnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "420f69d0-02c6-4404-8491-bd131ba460a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricnn_model.compile(\n",
    "    optimizer='nadam',\n",
    "    loss='mse',\n",
    "    metrics=['mse']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22aa7a7a-4a8f-4a85-8f82-06e4e9319726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "Epoch 1/10\n",
      "1064/1065 [============================>.] - ETA: 0s - loss: 0.3721 - mse: 0.3576WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "1065/1065 [==============================] - 75s 66ms/step - loss: 0.3721 - mse: 0.3576 - val_loss: 0.1915 - val_mse: 0.1790\n",
      "Epoch 2/10\n",
      "1065/1065 [==============================] - 69s 65ms/step - loss: 0.1418 - mse: 0.1307 - val_loss: 0.0740 - val_mse: 0.0644\n",
      "Epoch 3/10\n",
      "1065/1065 [==============================] - 70s 65ms/step - loss: 0.0923 - mse: 0.0838 - val_loss: 0.0603 - val_mse: 0.0527\n",
      "Epoch 4/10\n",
      "1065/1065 [==============================] - 70s 65ms/step - loss: 0.0713 - mse: 0.0645 - val_loss: 0.0548 - val_mse: 0.0488\n",
      "Epoch 5/10\n",
      "1065/1065 [==============================] - 70s 65ms/step - loss: 0.0555 - mse: 0.0501 - val_loss: 0.0564 - val_mse: 0.0514\n",
      "Epoch 6/10\n",
      "1065/1065 [==============================] - 70s 65ms/step - loss: 0.0474 - mse: 0.0430 - val_loss: 0.0459 - val_mse: 0.0421\n",
      "Epoch 7/10\n",
      "1065/1065 [==============================] - 69s 65ms/step - loss: 0.0365 - mse: 0.0330 - val_loss: 0.0690 - val_mse: 0.0658\n",
      "Epoch 8/10\n",
      "1065/1065 [==============================] - 70s 65ms/step - loss: 0.0373 - mse: 0.0344 - val_loss: 0.0450 - val_mse: 0.0424\n",
      "Epoch 9/10\n",
      "1065/1065 [==============================] - 70s 65ms/step - loss: 0.0313 - mse: 0.0288 - val_loss: 0.0474 - val_mse: 0.0452\n",
      "Epoch 10/10\n",
      "1065/1065 [==============================] - 70s 65ms/step - loss: 0.0290 - mse: 0.0270 - val_loss: 0.0414 - val_mse: 0.0395\n"
     ]
    }
   ],
   "source": [
    "ricnn_history = ricnn_model.fit(x=input_train_norm, y=output_train_norm, epochs=10, validation_data=(input_val_norm, output_val_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bafe0b6b-989d-4f90-894c-19c51553a8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.1094 - mse: 0.1094\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "406/406 [==============================] - 9s 23ms/step - loss: 0.1034 - mse: 0.1034\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "406/406 [==============================] - 9s 22ms/step - loss: 0.0539 - mse: 0.0520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05393340066075325, 0.05203879624605179]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.evaluate(input_test_norm, output_test_norm)\n",
    "lricnn_model.evaluate(input_test_norm, output_test_norm)\n",
    "ricnn_model.evaluate(input_test_norm, output_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79680b28-b6e5-4166-90f3-72c17f637e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-storm-mode]",
   "language": "python",
   "name": "conda-env-.conda-storm-mode-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
