{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c382a586-0788-4082-ac32-8e0d5b57fc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "from tensorflow.keras import layers, models\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imports.GDL_layers as GDL_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3215de71-47ec-42e4-9ee1-3d8f3d73edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a list of all the datafiles\n",
    "patch_path = \"/glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/\"\n",
    "patch_files = sorted(glob(join(patch_path, \"*.nc\")))\n",
    "patch_ds = xr.open_dataset(patch_files[0])\n",
    "csv_path = \"/glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/\"\n",
    "csv_files = sorted(glob(join(csv_path, \"track_step_*.csv\")))\n",
    "meta_ds = pd.read_csv(csv_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f10a4600-43c3-49f1-8d52-b64657768946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20101024-0000_d01_model_patches.nc\n",
      "Train 10, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20110201-0000_d01_model_patches.nc\n",
      "Train 20, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20110326-0000_d01_model_patches.nc\n",
      "Train 30, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20110414-0000_d01_model_patches.nc\n",
      "Train 40, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20110425-0000_d01_model_patches.nc\n",
      "Train 50, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20110522-0000_d01_model_patches.nc\n",
      "Train 60, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20110605-0000_d01_model_patches.nc\n",
      "Train 70, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20110615-0000_d01_model_patches.nc\n",
      "Train 80, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20110625-0000_d01_model_patches.nc\n",
      "Train 90, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20110712-0000_d01_model_patches.nc\n",
      "Train 100, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20120218-0000_d01_model_patches.nc\n",
      "Validation 105, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20120315-0000_d01_model_patches.nc\n",
      "Validation 115, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20120401-0000_d01_model_patches.nc\n",
      "Test 120, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20120409-0000_d01_model_patches.nc\n",
      "Test 130, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20120503-0000_d01_model_patches.nc\n",
      "Test 140, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_nc_refl/NCARSTORM_20120529-0000_d01_model_patches.nc\n"
     ]
    }
   ],
   "source": [
    "# Pull selected variables from patch files and join into a single DataSet\n",
    "num_files = 150\n",
    "train_split = int(num_files*0.7)\n",
    "val_split = int(num_files*0.8)\n",
    "variables = [\"REFL_COM_curr\", \"masks\"]\n",
    "data_list = []\n",
    "for p, patch_file in enumerate(patch_files[0:train_split]):\n",
    "    if p % 10 == 0:\n",
    "        print(f'Train {p}, {patch_file}')\n",
    "    ds = xr.open_dataset(patch_file)\n",
    "    data_list.append(ds[variables].compute())\n",
    "    ds.close()\n",
    "input_train = xr.concat(data_list, dim=\"p\")[\"REFL_COM_curr\"].expand_dims(\"channel\", axis = -1)\n",
    "train_masks = xr.concat(data_list, dim=\"p\")[\"masks\"]\n",
    "data_list = []\n",
    "for p, patch_file in enumerate(patch_files[train_split:val_split]):\n",
    "    if p % 10 == 0:\n",
    "        print(f'Validation {train_split + p}, {patch_file}')\n",
    "    ds = xr.open_dataset(patch_file)\n",
    "    data_list.append(ds[variables].compute())\n",
    "    ds.close()\n",
    "input_val = xr.concat(data_list, dim=\"p\")[\"REFL_COM_curr\"].expand_dims(\"channel\", axis = -1)\n",
    "val_masks = xr.concat(data_list, dim=\"p\")[\"masks\"]\n",
    "data_list = []\n",
    "for p, patch_file in enumerate(patch_files[val_split:num_files]):\n",
    "    if p % 10 == 0:\n",
    "        print(f'Test {val_split + p}, {patch_file}')\n",
    "    ds = xr.open_dataset(patch_file)\n",
    "    data_list.append(ds[variables].compute())\n",
    "    ds.close()\n",
    "input_test = xr.concat(data_list, dim=\"p\")[\"REFL_COM_curr\"].expand_dims(\"channel\", axis = -1)\n",
    "test_masks = xr.concat(data_list, dim=\"p\")[\"masks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eef87aa-7f51-48ff-8c77-fca32f52313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20101024-0000.csv\n",
      "Train 10, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20110201-0000.csv\n",
      "Train 20, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20110326-0000.csv\n",
      "Train 30, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20110414-0000.csv\n",
      "Train 40, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20110425-0000.csv\n",
      "Train 50, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20110522-0000.csv\n",
      "Train 60, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20110605-0000.csv\n",
      "Train 70, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20110615-0000.csv\n",
      "Train 80, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20110625-0000.csv\n",
      "Train 90, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20110712-0000.csv\n",
      "Train 100, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20120218-0000.csv\n",
      "Validation 105, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20120315-0000.csv\n",
      "Validation 115, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20120401-0000.csv\n",
      "Test 120, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20120409-0000.csv\n",
      "Test 130, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20120503-0000.csv\n",
      "Test 140, /glade/scratch/lverhoef/WRF_all/track_data_hrrr_3km_csv_refl/track_step_NCARSTORM_d01_20120529-0000.csv\n"
     ]
    }
   ],
   "source": [
    "# Pull variables from csv files and join into an array\n",
    "csv_variables = [\"major_axis_length\", \"minor_axis_length\"]\n",
    "csv_data_list = []\n",
    "for p, csv_file in enumerate(csv_files[0:train_split]):\n",
    "    if p % 10 == 0:\n",
    "        print(f'Train {p}, {csv_file}')\n",
    "    csv_ds = pd.read_csv(csv_file)\n",
    "    csv_data_list.append(csv_ds[csv_variables].to_xarray().rename({'index': 'p'}))\n",
    "output_train = xr.concat(csv_data_list, dim=\"p\").to_array().transpose()\n",
    "csv_data_list = []\n",
    "for p, csv_file in enumerate(csv_files[train_split:val_split]):\n",
    "    if p % 10 == 0:\n",
    "        print(f'Validation {train_split + p}, {csv_file}')\n",
    "    csv_ds = pd.read_csv(csv_file)\n",
    "    csv_data_list.append(csv_ds[csv_variables].to_xarray().rename({'index': 'p'}))\n",
    "output_val = xr.concat(csv_data_list, dim=\"p\").to_array().transpose()\n",
    "csv_data_list = []\n",
    "for p, csv_file in enumerate(csv_files[val_split:num_files]):\n",
    "    if p % 10 == 0:\n",
    "        print(f'Test {val_split + p}, {csv_file}')\n",
    "    csv_ds = pd.read_csv(csv_file)\n",
    "    csv_data_list.append(csv_ds[csv_variables].to_xarray().rename({'index': 'p'}))\n",
    "output_test = xr.concat(csv_data_list, dim=\"p\").to_array().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a33c86c-774e-4742-b98b-5b45130ee9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34061, 144, 144, 1)\n",
      "(4300, 144, 144, 1)\n",
      "(12985, 144, 144, 1)\n",
      "(34061, 2)\n",
      "(4300, 2)\n",
      "(12985, 2)\n"
     ]
    }
   ],
   "source": [
    "print(input_train.shape)\n",
    "print(input_val.shape)\n",
    "print(input_test.shape)\n",
    "print(output_train.shape)\n",
    "print(output_val.shape)\n",
    "print(output_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9ad7e74-ae51-4d6e-bdbf-b42fbf88ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the training data\n",
    "scale_stats = pd.DataFrame(index=[0], columns=[\"mean\", \"sd\"])\n",
    "scale_stats.loc[0, \"mean\"] = input_train.mean()\n",
    "scale_stats.loc[0, \"sd\"] = input_train.std()\n",
    "input_train_norm = (input_train - scale_stats.loc[0, \"mean\"]) / scale_stats.loc[0, \"sd\"]\n",
    "input_val_norm = (input_val - scale_stats.loc[0, \"mean\"]) / scale_stats.loc[0, \"sd\"]\n",
    "input_test_norm = (input_test - scale_stats.loc[0, \"mean\"]) / scale_stats.loc[0, \"sd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95788ec1-4803-4aff-aa8e-84c05ce30e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize output data\n",
    "output_scale_stats = pd.DataFrame(index=[0], columns=[\"mean\", \"sd\"])\n",
    "output_scale_stats.loc[0, \"mean\"] = output_train.mean()\n",
    "output_scale_stats.loc[0, \"sd\"] = output_train.std()\n",
    "output_train_norm = (output_train - output_scale_stats.loc[0, \"mean\"]) / output_scale_stats.loc[0, \"sd\"]\n",
    "output_val_norm = (output_val - output_scale_stats.loc[0, \"mean\"]) / output_scale_stats.loc[0, \"sd\"]\n",
    "output_test_norm = (output_test - output_scale_stats.loc[0, \"mean\"]) / output_scale_stats.loc[0, \"sd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e7ebf37-b8d9-4e9c-963c-e7ccfc8a5cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 08:26:21.775249: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-25 08:26:28.244527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30988 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:61:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "ricnn_backbone = models.Sequential()\n",
    "ricnn_backbone.add(GDL_layers.RotEquivConv2D(32, (3, 3), rot_axis=False, input_shape=(144, 144, 1)))\n",
    "ricnn_backbone.add(GDL_layers.RotEquivPool2D((2, 2)))\n",
    "ricnn_backbone.add(GDL_layers.RotEquivConv2D(32, (3, 3)))\n",
    "ricnn_backbone.add(GDL_layers.RotEquivPool2D((2, 2)))\n",
    "ricnn_backbone.add(GDL_layers.RotEquivConv2D(64, (3, 3)))\n",
    "ricnn_backbone.add(GDL_layers.RotEquivPool2D((2, 2)))\n",
    "ricnn_backbone.add(GDL_layers.RotEquivConv2D(64, (3, 3)))\n",
    "ricnn_backbone.add(GDL_layers.RotEquivPool2D((2, 2)))\n",
    "ricnn_backbone.add(GDL_layers.RotEquivConv2D(128, (3, 3)))\n",
    "ricnn_backbone.add(GDL_layers.RotInvPool())\n",
    "ricnn_backbone.add(layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e544f6a4-9369-42c1-8286-bdb364ac7c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rot_equiv_conv2d (RotEquivC  (None, 142, 142, 4, 32)  320       \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " rot_equiv_pool2d (RotEquivP  (None, 71, 71, 4, 32)    0         \n",
      " ool2D)                                                          \n",
      "                                                                 \n",
      " rot_equiv_conv2d_1 (RotEqui  (None, 69, 69, 4, 32)    9248      \n",
      " vConv2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_pool2d_1 (RotEqui  (None, 34, 34, 4, 32)    0         \n",
      " vPool2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_conv2d_2 (RotEqui  (None, 32, 32, 4, 64)    18496     \n",
      " vConv2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_pool2d_2 (RotEqui  (None, 16, 16, 4, 64)    0         \n",
      " vPool2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_conv2d_3 (RotEqui  (None, 14, 14, 4, 64)    36928     \n",
      " vConv2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_pool2d_3 (RotEqui  (None, 7, 7, 4, 64)      0         \n",
      " vPool2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_conv2d_4 (RotEqui  (None, 5, 5, 4, 128)     73856     \n",
      " vConv2D)                                                        \n",
      "                                                                 \n",
      " rot_inv_pool (RotInvPool)   (None, 5, 5, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3200)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,848\n",
      "Trainable params: 138,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ricnn_backbone.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fa0fca9-7db0-435b-8310-257ef53097d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_backbone = models.Sequential()\n",
    "cnn_backbone.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(144, 144, 1)))\n",
    "cnn_backbone.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_backbone.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "cnn_backbone.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_backbone.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn_backbone.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_backbone.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn_backbone.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_backbone.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "cnn_backbone.add(layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3eea481-1265-4bac-a4a9-6c2001d03650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 142, 142, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 71, 71, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 69, 69, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 34, 34, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 5, 5, 128)         73856     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3200)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,848\n",
      "Trainable params: 138,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_backbone.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12d24ae7-8a1e-4b3f-8042-6c291f744eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "head = models.Sequential()\n",
    "head.add(layers.Dense(32, input_shape=(3200,)))\n",
    "head.add(layers.LeakyReLU(alpha=0.05))\n",
    "head.add(layers.Dense(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5039296d-0018-4a03-89ee-48228e92df09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                102432    \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102,498\n",
      "Trainable params: 102,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "head.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11bcc61a-0f29-45ad-86cd-5aec8c87cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = models.Sequential()\n",
    "cnn_model.add(cnn_backbone)\n",
    "cnn_model.add(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e26dd17c-52d7-439e-ac03-ba838ca7271e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_1 (Sequential)   (None, 3200)              138848    \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, 2)                 102498    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 241,346\n",
      "Trainable params: 241,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c333dbb-cb5d-4d98-801b-0e41343ca6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mse']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c1633e5-64e9-43a9-9c62-bb56995db659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 08:26:41.188995: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1065/1065 [==============================] - ETA: 0s - loss: 0.2842 - mse: 0.2842WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "1065/1065 [==============================] - 53s 16ms/step - loss: 0.2842 - mse: 0.2842 - val_loss: 0.1451 - val_mse: 0.1451\n",
      "Epoch 2/10\n",
      "1065/1065 [==============================] - 16s 15ms/step - loss: 0.1579 - mse: 0.1579 - val_loss: 0.0908 - val_mse: 0.0908\n",
      "Epoch 3/10\n",
      "1065/1065 [==============================] - 16s 15ms/step - loss: 0.1143 - mse: 0.1143 - val_loss: 0.0846 - val_mse: 0.0846\n",
      "Epoch 4/10\n",
      "1065/1065 [==============================] - 16s 15ms/step - loss: 0.0879 - mse: 0.0879 - val_loss: 0.1131 - val_mse: 0.1131\n",
      "Epoch 5/10\n",
      "1065/1065 [==============================] - 16s 15ms/step - loss: 0.0702 - mse: 0.0702 - val_loss: 0.0659 - val_mse: 0.0659\n",
      "Epoch 6/10\n",
      "1065/1065 [==============================] - 17s 16ms/step - loss: 0.0584 - mse: 0.0584 - val_loss: 0.0614 - val_mse: 0.0614\n",
      "Epoch 7/10\n",
      "1065/1065 [==============================] - 17s 16ms/step - loss: 0.0476 - mse: 0.0476 - val_loss: 0.0566 - val_mse: 0.0566\n",
      "Epoch 8/10\n",
      "1065/1065 [==============================] - 17s 16ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0718 - val_mse: 0.0718\n",
      "Epoch 9/10\n",
      "1065/1065 [==============================] - 17s 16ms/step - loss: 0.0413 - mse: 0.0413 - val_loss: 0.0649 - val_mse: 0.0649\n",
      "Epoch 10/10\n",
      "1065/1065 [==============================] - 17s 16ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0461 - val_mse: 0.0461\n"
     ]
    }
   ],
   "source": [
    "cnn_hist = cnn_model.fit(x=input_train_norm, y=output_train_norm, epochs=10, validation_data=(input_val_norm, output_val_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2c0d2d4-5efd-4564-bf4f-f0b1add0bc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "1065/1065 [==============================] - 9s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "cnn_latent_train = cnn_backbone.predict(input_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e53367fd-571d-495f-a54e-9a6bc84b977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricnn_backbone.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mse']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e842a53-c87b-49f5-8297-df9eb15d60d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "Epoch 1/10\n",
      "1065/1065 [==============================] - 81s 71ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 2/10\n",
      "1065/1065 [==============================] - 76s 71ms/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 3/10\n",
      "1065/1065 [==============================] - 76s 71ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 4/10\n",
      "1065/1065 [==============================] - 74s 70ms/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 5/10\n",
      "1065/1065 [==============================] - 74s 70ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 6/10\n",
      "1065/1065 [==============================] - 76s 71ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 7/10\n",
      "1065/1065 [==============================] - 74s 70ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 8/10\n",
      "1065/1065 [==============================] - 76s 71ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 9/10\n",
      "1065/1065 [==============================] - 75s 71ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 10/10\n",
      "1065/1065 [==============================] - 76s 71ms/step - loss: 0.0043 - mse: 0.0043\n"
     ]
    }
   ],
   "source": [
    "latent_ricnn_cnn_hist = ricnn_backbone.fit(x=input_train_norm, y=cnn_latent_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b808ffc1-7c0a-41f0-8eb6-b369561a5ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b4526dfcbe0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "F, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.plot(latent_ricnn_cnn_hist.history['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d585a7f-0075-458b-95fb-4de7fc1599fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lricnn_model = models.Sequential()\n",
    "lricnn_model.add(ricnn_backbone)\n",
    "lricnn_model.add(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb6db518-6841-4709-8606-426fd2683f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lricnn_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mse']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11d6df22-83ee-479b-8a6e-65b69cd433a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 3200)              138848    \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, 2)                 102498    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 241,346\n",
      "Trainable params: 241,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lricnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f56f0ad-bf3a-4c17-b80a-53320dd47717",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricnn_model = models.Sequential()\n",
    "ricnn_model.add(GDL_layers.RotEquivConv2D(32, (3, 3), rot_axis=False, kernel_regularizer='L2', input_shape=(144, 144, 1)))\n",
    "ricnn_model.add(GDL_layers.RotEquivPool2D((2, 2)))\n",
    "ricnn_model.add(GDL_layers.RotEquivConv2D(32, (3, 3)))\n",
    "ricnn_model.add(GDL_layers.RotEquivPool2D((2, 2)))\n",
    "ricnn_model.add(GDL_layers.RotEquivConv2D(64, (3, 3)))\n",
    "ricnn_model.add(GDL_layers.RotEquivPool2D((2, 2)))\n",
    "ricnn_model.add(GDL_layers.RotEquivConv2D(64, (3, 3)))\n",
    "ricnn_model.add(GDL_layers.RotEquivPool2D((2, 2)))\n",
    "ricnn_model.add(GDL_layers.RotEquivConv2D(128, (3, 3)))\n",
    "ricnn_model.add(GDL_layers.RotInvPool())\n",
    "ricnn_model.add(layers.Flatten())\n",
    "ricnn_model.add(layers.Dense(32, activation='relu'))\n",
    "ricnn_model.add(layers.Dense(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5875404d-3a75-443f-b10b-ba5f1457232c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rot_equiv_conv2d_5 (RotEqui  (None, 142, 142, 4, 32)  320       \n",
      " vConv2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_pool2d_4 (RotEqui  (None, 71, 71, 4, 32)    0         \n",
      " vPool2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_conv2d_6 (RotEqui  (None, 69, 69, 4, 32)    9248      \n",
      " vConv2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_pool2d_5 (RotEqui  (None, 34, 34, 4, 32)    0         \n",
      " vPool2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_conv2d_7 (RotEqui  (None, 32, 32, 4, 64)    18496     \n",
      " vConv2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_pool2d_6 (RotEqui  (None, 16, 16, 4, 64)    0         \n",
      " vPool2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_conv2d_8 (RotEqui  (None, 14, 14, 4, 64)    36928     \n",
      " vConv2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_pool2d_7 (RotEqui  (None, 7, 7, 4, 64)      0         \n",
      " vPool2D)                                                        \n",
      "                                                                 \n",
      " rot_equiv_conv2d_9 (RotEqui  (None, 5, 5, 4, 128)     73856     \n",
      " vConv2D)                                                        \n",
      "                                                                 \n",
      " rot_inv_pool_1 (RotInvPool)  (None, 5, 5, 128)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 3200)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                102432    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 241,346\n",
      "Trainable params: 241,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ricnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "420f69d0-02c6-4404-8491-bd131ba460a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricnn_model.compile(\n",
    "    optimizer='nadam',\n",
    "    loss='mse',\n",
    "    metrics=['mse']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22aa7a7a-4a8f-4a85-8f82-06e4e9319726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "Epoch 1/10\n",
      "1064/1065 [============================>.] - ETA: 0s - loss: 0.3328 - mse: 0.3159WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "1065/1065 [==============================] - 83s 73ms/step - loss: 0.3327 - mse: 0.3157 - val_loss: 0.1234 - val_mse: 0.1086\n",
      "Epoch 2/10\n",
      "1065/1065 [==============================] - 76s 72ms/step - loss: 0.1231 - mse: 0.1104 - val_loss: 0.0796 - val_mse: 0.0689\n",
      "Epoch 3/10\n",
      "1065/1065 [==============================] - 76s 71ms/step - loss: 0.0813 - mse: 0.0720 - val_loss: 0.0547 - val_mse: 0.0466\n",
      "Epoch 4/10\n",
      "1065/1065 [==============================] - 77s 72ms/step - loss: 0.0610 - mse: 0.0540 - val_loss: 0.0524 - val_mse: 0.0461\n",
      "Epoch 5/10\n",
      "1065/1065 [==============================] - 76s 71ms/step - loss: 0.0465 - mse: 0.0411 - val_loss: 0.0484 - val_mse: 0.0436\n",
      "Epoch 6/10\n",
      "1065/1065 [==============================] - 76s 71ms/step - loss: 0.0392 - mse: 0.0350 - val_loss: 0.0443 - val_mse: 0.0406\n",
      "Epoch 7/10\n",
      "1065/1065 [==============================] - 76s 72ms/step - loss: 0.0542 - mse: 0.0505 - val_loss: 0.0409 - val_mse: 0.0376\n",
      "Epoch 8/10\n",
      "1065/1065 [==============================] - 76s 71ms/step - loss: 0.0311 - mse: 0.0281 - val_loss: 0.0407 - val_mse: 0.0380\n",
      "Epoch 9/10\n",
      "1065/1065 [==============================] - 76s 71ms/step - loss: 0.0617 - mse: 0.0586 - val_loss: 0.0562 - val_mse: 0.0533\n",
      "Epoch 10/10\n",
      "1065/1065 [==============================] - 76s 71ms/step - loss: 0.0304 - mse: 0.0278 - val_loss: 0.0528 - val_mse: 0.0506\n"
     ]
    }
   ],
   "source": [
    "ricnn_history = ricnn_model.fit(x=input_train_norm, y=output_train_norm, epochs=10, validation_data=(input_val_norm, output_val_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bafe0b6b-989d-4f90-894c-19c51553a8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "406/406 [==============================] - 4s 10ms/step - loss: 0.0638 - mse: 0.0638\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "406/406 [==============================] - 12s 27ms/step - loss: 0.1057 - mse: 0.1057\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "406/406 [==============================] - 11s 27ms/step - loss: 0.0644 - mse: 0.0622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06439657509326935, 0.06221342831850052]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.evaluate(input_test_norm, output_test_norm)\n",
    "lricnn_model.evaluate(input_test_norm, output_test_norm)\n",
    "ricnn_model.evaluate(input_test_norm, output_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79680b28-b6e5-4166-90f3-72c17f637e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-storm-mode]",
   "language": "python",
   "name": "conda-env-.conda-storm-mode-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
